{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3efe8230-a279-4202-8f5d-8f576a23061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting einops\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git \n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6291aad-44ba-40eb-ae39-348d5447fc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shared-evans",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b/053e1a33a6e7043aefaa3f5d13c48269a5511cff/attention.py:157: UserWarning: Using `attn_impl: torch`. If your model does not use `alibi` or `prefix_lm` we recommend using `attn_impl: flash` otherwise we recommend using `attn_impl: triton`.\n",
      "  warnings.warn('Using `attn_impl: torch`. If your model does not use `alibi` or ' + '`prefix_lm` we recommend using `attn_impl: flash` otherwise ' + 'we recommend using `attn_impl: triton`.')\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/container/ucx/lib64'), PosixPath('/usr/lib/libibverbs'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib/libibverbs:/container/ucx/lib:/container/ucx/lib64:/container/ompi/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('false,\"propagation\"'), PosixPath('null},\"resources\"'), PosixPath('null,\"notebook_idle_type\"'), PosixPath('{\"cuda\"'), PosixPath('null,\"force_pull_image\"'), PosixPath('null,\"idle_timeout\"'), PosixPath('\"determinedai/environments'), PosixPath('{},\"ports\"'), PosixPath('null,\"add_capabilities\"'), PosixPath('\"compute-pool\",\"devices\"'), PosixPath('{\"slots\"'), PosixPath('\"/run/determined/workdir/shared_fs\",\"read_only\"'), PosixPath('1,\"resource_pool\"'), PosixPath('\"rprivate\"}],\"environment\"'), PosixPath('{},\"slurm\"'), PosixPath('[{\"host_path\"'), PosixPath('{\"description\"'), PosixPath('null},\"entrypoint\"'), PosixPath('false,\"pod_spec\"'), PosixPath('8,\"weight\"'), PosixPath('\"Andrew Participant Notebook \",\"bind_mounts\"'), PosixPath('{\"image\"'), PosixPath('\"/mnt/efs\",\"container_path\"'), PosixPath('null,\"drop_capabilities\"'), PosixPath('null,\"debug\"'), PosixPath('false,\"pbs\"'), PosixPath('cuda-11.3-pytorch-1.12-gpu-mpi-e3c3210\"},\"environment_variables\"'), PosixPath('{}}'), PosixPath('\"kernels_or_terminals\",\"work_dir\"')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/container/nccl/lib')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/container/ucx/lib64'), PosixPath('/usr/lib/libibverbs')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/container/nccl')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.192.10.226'), PosixPath('http'), PosixPath('8080')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/container/ofi/lib'), PosixPath('/usr/lib/libibverbs'), PosixPath('/container/ofi/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPTForCausalLM(\n",
       "  (transformer): MPTModel(\n",
       "    (wte): Embedding(50432, 4096)\n",
       "    (emb_drop): Dropout(p=0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear4bit(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm_f): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "# model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "#   'mosaicml/mpt-7b',\n",
    "#   trust_remote_code=True,\n",
    "#   torch_dtype=torch.bfloat16,\n",
    "    \n",
    "# )\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "model_id = 'mosaicml/mpt-7b'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, \n",
    "#                                              quantization_config=bnb_config, \n",
    "#                                              device_map={\"\":0},\n",
    "#                                             trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    load_in_4bit=True, \n",
    "    device_map='cuda:0',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "# model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb789364-6d22-4b6f-a8bf-df7499cf8cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.30.0.dev0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cooked-youth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun  1 21:22:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.74       Driver Version: 470.74       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    32W /  70W |   7308MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            On   | 00000000:19:00.0 Off |                    0 |\n",
      "| N/A   30C    P8     8W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            On   | 00000000:35:00.0 Off |                    0 |\n",
      "| N/A   32C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            On   | 00000000:36:00.0 Off |                    0 |\n",
      "| N/A   30C    P8     8W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla T4            On   | 00000000:E7:00.0 Off |                    0 |\n",
      "| N/A   31C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla T4            On   | 00000000:E8:00.0 Off |                    0 |\n",
      "| N/A   31C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla T4            On   | 00000000:F4:00.0 Off |                    0 |\n",
      "| N/A   32C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla T4            On   | 00000000:F5:00.0 Off |                    0 |\n",
      "| N/A   29C    P8     8W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spare-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelsize: 3428.1M parameters\n"
     ]
    }
   ],
   "source": [
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"Modelsize: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('mosaicml/mpt-7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becoming-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\\\n",
    "image_path = \"/mnt/image.png\"\n",
    "\n",
    "# load image\n",
    "\"\"\"\n",
    "tokenized_example = tokenizer(txt, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spectacular-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5695,    64,  3967,   426, 13357,    78,  2649,    16,  5695,    15,\n",
       "          8567,     3,   187,   187,     4,  3301,  2460,   187]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moved-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1448: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(tokenized_example['input_ids'], max_new_tokens=150, do_sample=False, top_k=5, top_p=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surface-arena",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path = \"/mnt/image.png\"\n",
      "\n",
      "# load image\n",
      "image = Image.open(image_path)\n",
      "\n",
      "# get image size\n",
      "width, height = image.size\n",
      "\n",
      "# get image size in pixels\n",
      "width, height = image.size\n",
      "\n",
      "# get image size in pixels\n",
      "width, height = image.size\n",
      "\n",
      "# get image size in pixels\n",
      "width, height = image.size\n",
      "\n",
      "# get image size in pixels\n",
      "width, height = image.size\n",
      "\n",
      "# get image size in pixels\n",
      "width, height = image.size\n",
      "\n",
      "# get image size in pixels\n",
      "width, height = image.size\n",
      "\n",
      "# get image size in pixels\n",
      "width, height = image.size\n",
      "\n",
      "# get image size in pixels\n",
      "width, height = image\n"
     ]
    }
   ],
   "source": [
    "answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(answer[0].rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "temporal-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_text = \"\"\"\\\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.read(image_path)\n",
    "\"\"\"\n",
    "tokenized_answer = tokenizer.encode(answer_text ,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e7e63b1-0225-4ae0-b349-38293b214612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_answer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aggressive-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**tokenized_example.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "vertical-seller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 50432])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tested-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8aa7376-8e9f-4f2d-9869-872e6db80597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 14.8984,  -0.6685,  16.4375,  ...,  -0.7480,  -0.7554,  -0.7432],\n",
       "         [ 25.2188,   9.3594,  25.2812,  ...,   9.3281,   9.3281,   9.3359],\n",
       "         [  8.3281, -10.2891,  10.3047,  ..., -10.5312, -10.5469, -10.5312],\n",
       "         ...,\n",
       "         [ 29.0625,  10.9609,  31.4062,  ...,  10.8047,  10.7969,  10.8047],\n",
       "         [ 39.2500,  18.0000,  41.5312,  ...,  17.8125,  17.8125,  17.8125],\n",
       "         [ 44.2812,  18.5312,  43.6875,  ...,  18.1875,  18.1875,  18.1875]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "functioning-minutes",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 907776])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_token_output = outputs.logits.view(1,-1)\n",
    "last_token_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "promising-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(554939, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(last_token_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "reported-republican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4064])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_answer.shape\n",
    "labels = tokenized_answer[0][0].view(1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "arctic-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight   Modelsize: 206.6M parameters\n",
      "transformer.wte.weight False\n",
      "transformer.blocks.0.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.0.norm_1.weight False\n",
      "transformer.blocks.0.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.0.attn.Wqkv.weight False\n",
      "transformer.blocks.0.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.0.attn.out_proj.weight False\n",
      "transformer.blocks.0.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.0.norm_2.weight False\n",
      "transformer.blocks.0.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.0.ffn.up_proj.weight False\n",
      "transformer.blocks.0.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.0.ffn.down_proj.weight False\n",
      "transformer.blocks.1.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.1.norm_1.weight False\n",
      "transformer.blocks.1.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.1.attn.Wqkv.weight False\n",
      "transformer.blocks.1.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.1.attn.out_proj.weight False\n",
      "transformer.blocks.1.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.1.norm_2.weight False\n",
      "transformer.blocks.1.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.1.ffn.up_proj.weight False\n",
      "transformer.blocks.1.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.1.ffn.down_proj.weight False\n",
      "transformer.blocks.2.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.2.norm_1.weight False\n",
      "transformer.blocks.2.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.2.attn.Wqkv.weight False\n",
      "transformer.blocks.2.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.2.attn.out_proj.weight False\n",
      "transformer.blocks.2.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.2.norm_2.weight False\n",
      "transformer.blocks.2.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.2.ffn.up_proj.weight False\n",
      "transformer.blocks.2.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.2.ffn.down_proj.weight False\n",
      "transformer.blocks.3.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.3.norm_1.weight False\n",
      "transformer.blocks.3.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.3.attn.Wqkv.weight False\n",
      "transformer.blocks.3.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.3.attn.out_proj.weight False\n",
      "transformer.blocks.3.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.3.norm_2.weight False\n",
      "transformer.blocks.3.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.3.ffn.up_proj.weight False\n",
      "transformer.blocks.3.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.3.ffn.down_proj.weight False\n",
      "transformer.blocks.4.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.4.norm_1.weight False\n",
      "transformer.blocks.4.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.4.attn.Wqkv.weight False\n",
      "transformer.blocks.4.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.4.attn.out_proj.weight False\n",
      "transformer.blocks.4.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.4.norm_2.weight False\n",
      "transformer.blocks.4.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.4.ffn.up_proj.weight False\n",
      "transformer.blocks.4.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.4.ffn.down_proj.weight False\n",
      "transformer.blocks.5.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.5.norm_1.weight False\n",
      "transformer.blocks.5.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.5.attn.Wqkv.weight False\n",
      "transformer.blocks.5.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.5.attn.out_proj.weight False\n",
      "transformer.blocks.5.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.5.norm_2.weight False\n",
      "transformer.blocks.5.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.5.ffn.up_proj.weight False\n",
      "transformer.blocks.5.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.5.ffn.down_proj.weight False\n",
      "transformer.blocks.6.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.6.norm_1.weight False\n",
      "transformer.blocks.6.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.6.attn.Wqkv.weight False\n",
      "transformer.blocks.6.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.6.attn.out_proj.weight False\n",
      "transformer.blocks.6.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.6.norm_2.weight False\n",
      "transformer.blocks.6.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.6.ffn.up_proj.weight False\n",
      "transformer.blocks.6.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.6.ffn.down_proj.weight False\n",
      "transformer.blocks.7.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.7.norm_1.weight False\n",
      "transformer.blocks.7.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.7.attn.Wqkv.weight False\n",
      "transformer.blocks.7.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.7.attn.out_proj.weight False\n",
      "transformer.blocks.7.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.7.norm_2.weight False\n",
      "transformer.blocks.7.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.7.ffn.up_proj.weight False\n",
      "transformer.blocks.7.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.7.ffn.down_proj.weight False\n",
      "transformer.blocks.8.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.8.norm_1.weight False\n",
      "transformer.blocks.8.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.8.attn.Wqkv.weight False\n",
      "transformer.blocks.8.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.8.attn.out_proj.weight False\n",
      "transformer.blocks.8.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.8.norm_2.weight False\n",
      "transformer.blocks.8.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.8.ffn.up_proj.weight False\n",
      "transformer.blocks.8.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.8.ffn.down_proj.weight False\n",
      "transformer.blocks.9.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.9.norm_1.weight False\n",
      "transformer.blocks.9.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.9.attn.Wqkv.weight False\n",
      "transformer.blocks.9.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.9.attn.out_proj.weight False\n",
      "transformer.blocks.9.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.9.norm_2.weight False\n",
      "transformer.blocks.9.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.9.ffn.up_proj.weight False\n",
      "transformer.blocks.9.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.9.ffn.down_proj.weight False\n",
      "transformer.blocks.10.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.10.norm_1.weight False\n",
      "transformer.blocks.10.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.10.attn.Wqkv.weight False\n",
      "transformer.blocks.10.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.10.attn.out_proj.weight False\n",
      "transformer.blocks.10.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.10.norm_2.weight False\n",
      "transformer.blocks.10.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.10.ffn.up_proj.weight False\n",
      "transformer.blocks.10.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.10.ffn.down_proj.weight False\n",
      "transformer.blocks.11.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.11.norm_1.weight False\n",
      "transformer.blocks.11.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.11.attn.Wqkv.weight False\n",
      "transformer.blocks.11.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.11.attn.out_proj.weight False\n",
      "transformer.blocks.11.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.11.norm_2.weight False\n",
      "transformer.blocks.11.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.11.ffn.up_proj.weight False\n",
      "transformer.blocks.11.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.11.ffn.down_proj.weight False\n",
      "transformer.blocks.12.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.12.norm_1.weight False\n",
      "transformer.blocks.12.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.12.attn.Wqkv.weight False\n",
      "transformer.blocks.12.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.12.attn.out_proj.weight False\n",
      "transformer.blocks.12.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.12.norm_2.weight False\n",
      "transformer.blocks.12.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.12.ffn.up_proj.weight False\n",
      "transformer.blocks.12.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.12.ffn.down_proj.weight False\n",
      "transformer.blocks.13.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.13.norm_1.weight False\n",
      "transformer.blocks.13.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.13.attn.Wqkv.weight False\n",
      "transformer.blocks.13.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.13.attn.out_proj.weight False\n",
      "transformer.blocks.13.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.13.norm_2.weight False\n",
      "transformer.blocks.13.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.13.ffn.up_proj.weight False\n",
      "transformer.blocks.13.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.13.ffn.down_proj.weight False\n",
      "transformer.blocks.14.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.14.norm_1.weight False\n",
      "transformer.blocks.14.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.14.attn.Wqkv.weight False\n",
      "transformer.blocks.14.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.14.attn.out_proj.weight False\n",
      "transformer.blocks.14.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.14.norm_2.weight False\n",
      "transformer.blocks.14.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.14.ffn.up_proj.weight False\n",
      "transformer.blocks.14.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.14.ffn.down_proj.weight False\n",
      "transformer.blocks.15.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.15.norm_1.weight False\n",
      "transformer.blocks.15.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.15.attn.Wqkv.weight False\n",
      "transformer.blocks.15.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.15.attn.out_proj.weight False\n",
      "transformer.blocks.15.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.15.norm_2.weight False\n",
      "transformer.blocks.15.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.15.ffn.up_proj.weight False\n",
      "transformer.blocks.15.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.15.ffn.down_proj.weight False\n",
      "transformer.blocks.16.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.16.norm_1.weight False\n",
      "transformer.blocks.16.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.16.attn.Wqkv.weight False\n",
      "transformer.blocks.16.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.16.attn.out_proj.weight False\n",
      "transformer.blocks.16.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.16.norm_2.weight False\n",
      "transformer.blocks.16.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.16.ffn.up_proj.weight False\n",
      "transformer.blocks.16.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.16.ffn.down_proj.weight False\n",
      "transformer.blocks.17.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.17.norm_1.weight False\n",
      "transformer.blocks.17.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.17.attn.Wqkv.weight False\n",
      "transformer.blocks.17.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.17.attn.out_proj.weight False\n",
      "transformer.blocks.17.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.17.norm_2.weight False\n",
      "transformer.blocks.17.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.17.ffn.up_proj.weight False\n",
      "transformer.blocks.17.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.17.ffn.down_proj.weight False\n",
      "transformer.blocks.18.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.18.norm_1.weight False\n",
      "transformer.blocks.18.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.18.attn.Wqkv.weight False\n",
      "transformer.blocks.18.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.18.attn.out_proj.weight False\n",
      "transformer.blocks.18.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.18.norm_2.weight False\n",
      "transformer.blocks.18.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.18.ffn.up_proj.weight False\n",
      "transformer.blocks.18.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.18.ffn.down_proj.weight False\n",
      "transformer.blocks.19.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.19.norm_1.weight False\n",
      "transformer.blocks.19.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.19.attn.Wqkv.weight False\n",
      "transformer.blocks.19.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.19.attn.out_proj.weight False\n",
      "transformer.blocks.19.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.19.norm_2.weight False\n",
      "transformer.blocks.19.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.19.ffn.up_proj.weight False\n",
      "transformer.blocks.19.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.19.ffn.down_proj.weight False\n",
      "transformer.blocks.20.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.20.norm_1.weight False\n",
      "transformer.blocks.20.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.20.attn.Wqkv.weight False\n",
      "transformer.blocks.20.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.20.attn.out_proj.weight False\n",
      "transformer.blocks.20.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.20.norm_2.weight False\n",
      "transformer.blocks.20.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.20.ffn.up_proj.weight False\n",
      "transformer.blocks.20.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.20.ffn.down_proj.weight False\n",
      "transformer.blocks.21.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.21.norm_1.weight False\n",
      "transformer.blocks.21.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.21.attn.Wqkv.weight False\n",
      "transformer.blocks.21.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.21.attn.out_proj.weight False\n",
      "transformer.blocks.21.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.21.norm_2.weight False\n",
      "transformer.blocks.21.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.21.ffn.up_proj.weight False\n",
      "transformer.blocks.21.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.21.ffn.down_proj.weight False\n",
      "transformer.blocks.22.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.22.norm_1.weight False\n",
      "transformer.blocks.22.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.22.attn.Wqkv.weight False\n",
      "transformer.blocks.22.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.22.attn.out_proj.weight False\n",
      "transformer.blocks.22.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.22.norm_2.weight False\n",
      "transformer.blocks.22.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.22.ffn.up_proj.weight False\n",
      "transformer.blocks.22.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.22.ffn.down_proj.weight False\n",
      "transformer.blocks.23.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.23.norm_1.weight False\n",
      "transformer.blocks.23.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.23.attn.Wqkv.weight False\n",
      "transformer.blocks.23.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.23.attn.out_proj.weight False\n",
      "transformer.blocks.23.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.23.norm_2.weight False\n",
      "transformer.blocks.23.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.23.ffn.up_proj.weight False\n",
      "transformer.blocks.23.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.23.ffn.down_proj.weight False\n",
      "transformer.blocks.24.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.24.norm_1.weight False\n",
      "transformer.blocks.24.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.24.attn.Wqkv.weight False\n",
      "transformer.blocks.24.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.24.attn.out_proj.weight False\n",
      "transformer.blocks.24.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.24.norm_2.weight False\n",
      "transformer.blocks.24.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.24.ffn.up_proj.weight False\n",
      "transformer.blocks.24.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.24.ffn.down_proj.weight False\n",
      "transformer.blocks.25.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.25.norm_1.weight False\n",
      "transformer.blocks.25.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.25.attn.Wqkv.weight False\n",
      "transformer.blocks.25.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.25.attn.out_proj.weight False\n",
      "transformer.blocks.25.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.25.norm_2.weight False\n",
      "transformer.blocks.25.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.25.ffn.up_proj.weight False\n",
      "transformer.blocks.25.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.25.ffn.down_proj.weight False\n",
      "transformer.blocks.26.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.26.norm_1.weight False\n",
      "transformer.blocks.26.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.26.attn.Wqkv.weight False\n",
      "transformer.blocks.26.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.26.attn.out_proj.weight False\n",
      "transformer.blocks.26.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.26.norm_2.weight False\n",
      "transformer.blocks.26.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.26.ffn.up_proj.weight False\n",
      "transformer.blocks.26.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.26.ffn.down_proj.weight False\n",
      "transformer.blocks.27.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.27.norm_1.weight False\n",
      "transformer.blocks.27.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.27.attn.Wqkv.weight False\n",
      "transformer.blocks.27.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.27.attn.out_proj.weight False\n",
      "transformer.blocks.27.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.27.norm_2.weight False\n",
      "transformer.blocks.27.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.27.ffn.up_proj.weight False\n",
      "transformer.blocks.27.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.27.ffn.down_proj.weight False\n",
      "transformer.blocks.28.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.28.norm_1.weight False\n",
      "transformer.blocks.28.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.28.attn.Wqkv.weight False\n",
      "transformer.blocks.28.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.28.attn.out_proj.weight False\n",
      "transformer.blocks.28.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.28.norm_2.weight False\n",
      "transformer.blocks.28.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.28.ffn.up_proj.weight False\n",
      "transformer.blocks.28.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.28.ffn.down_proj.weight False\n",
      "transformer.blocks.29.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.29.norm_1.weight False\n",
      "transformer.blocks.29.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.29.attn.Wqkv.weight False\n",
      "transformer.blocks.29.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.29.attn.out_proj.weight False\n",
      "transformer.blocks.29.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.29.norm_2.weight False\n",
      "transformer.blocks.29.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.29.ffn.up_proj.weight False\n",
      "transformer.blocks.29.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.29.ffn.down_proj.weight False\n",
      "transformer.blocks.30.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.30.norm_1.weight False\n",
      "transformer.blocks.30.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.30.attn.Wqkv.weight False\n",
      "transformer.blocks.30.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.30.attn.out_proj.weight False\n",
      "transformer.blocks.30.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.30.norm_2.weight False\n",
      "transformer.blocks.30.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.30.ffn.up_proj.weight False\n",
      "transformer.blocks.30.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.30.ffn.down_proj.weight False\n",
      "transformer.blocks.31.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.31.norm_1.weight True\n",
      "transformer.blocks.31.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.31.attn.Wqkv.weight False\n",
      "transformer.blocks.31.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.31.attn.out_proj.weight False\n",
      "transformer.blocks.31.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.31.norm_2.weight True\n",
      "transformer.blocks.31.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.31.ffn.up_proj.weight False\n",
      "transformer.blocks.31.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.31.ffn.down_proj.weight False\n",
      "transformer.norm_f.weight   Modelsize: 0.0M parameters\n",
      "transformer.norm_f.weight False\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}   Modelsize: {param.numel()/1000**2:.1f}M parameters\")\n",
    "    if \"31\" not in name:\n",
    "        param.requires_grad = False\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "banned-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelsize: 201.3M parameters\n"
     ]
    }
   ],
   "source": [
    "params = sum(t.numel() for t in model.transformer.blocks[-1].parameters())\n",
    "print(f\"Modelsize: {params/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "retired-italic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lossfct = torch.nn.CrossEntropyLoss()\n",
    "optimizer = transformers.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d73cbc23-71fb-4818-8988-9dc7dfafc32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([907776])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_token_output[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "promising-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.Size([1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "labels = tokenized_answer[0][0].view(1)\n",
    "print(labels.dtype, labels.shape,last_token_output.float().dtype)\n",
    "loss = lossfct(last_token_output.float().to(\"cuda:0\"),labels.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "perfect-spiritual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.046722412109375"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "disabled-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad(set_to_none=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenized_example['input_ids'].to('cuda:0'), max_new_tokens=50, do_sample=False, top_k=5, top_p=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path = \"/mnt/image.png\"\n",
      "\n",
      "# load image\n",
      "img = cv2.imread(image_path)\n",
      "\n",
      "# convert to grayscale\n",
      "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "# blur\n",
      "blur =\n"
     ]
    }
   ],
   "source": [
    "answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(answer[0].rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996881e7-6f5d-4f73-b928-bca8def50ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
